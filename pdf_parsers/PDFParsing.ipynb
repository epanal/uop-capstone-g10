{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Parsing AHCM-HRSN screening PDFs"
      ],
      "metadata": {
        "id": "rJMjzpYGSuLa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tried various extractors before such as pymupdf, pypdf2 and pdfminer but wasn't getting the exact extractions as needed. So tried using two methods pdfplumber and tesseract OCR(pdfs converted to images and then text extracted from images). And pdfplumber has been the msot favorite by now."
      ],
      "metadata": {
        "id": "UX-4TvSCYF0p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Zum6F6suAZEc"
      },
      "outputs": [],
      "source": [
        "pip install pymupdf pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdf2image pytesseract pandas\n",
        "!apt-get install -y poppler-utils  # Required for pdf2image"
      ],
      "metadata": {
        "collapsed": true,
        "id": "GxyMvUg9AgEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "!apt-get install -y tesseract-ocr"
      ],
      "metadata": {
        "collapsed": true,
        "id": "xABXUNXLB0a3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytesseract\n",
        "!pip install pdf2image\n",
        "!pip install pillow"
      ],
      "metadata": {
        "collapsed": true,
        "id": "xcBigja1CAjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pytesseract\n",
        "\n",
        "# Set the correct Tesseract path\n",
        "pytesseract.pytesseract.tesseract_cmd = \"/usr/bin/tesseract\""
      ],
      "metadata": {
        "id": "V2s9j9d_CJab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Extraction using Tesseract OCR"
      ],
      "metadata": {
        "id": "Bp1YQZl_CTY1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. Extraction from a single pdf"
      ],
      "metadata": {
        "id": "34Gl5KoXCgMH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pytesseract\n",
        "import pandas as pd\n",
        "import re\n",
        "from pdf2image import convert_from_path"
      ],
      "metadata": {
        "id": "ArBFV0lLCQAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_path = \"/content/drive/MyDrive/ahcm_redacted/redacted_01cb6dae438c.pdf\""
      ],
      "metadata": {
        "id": "K5Pc1p84CwEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unwanted section headers and instruction blocks\n",
        "UNWANTED_TEXTS = [\n",
        "    \"Living Situation\", \"Food\", \"Transportation\", \"Utilities\", \"Safety\",\n",
        "    \"Financial Strain\", \"Employment\", \"Family and Community Support\", \"Education\",\n",
        "    \"Physical Activity\", \"Substance Use\", \"Mental Health\", \"Disabilities\",\n",
        "    \"Choose all the apply\",\n",
        "    \"Please answer whether the statements were OFTEN, SOMETIMES, or NEVER true for you and your household in the last 12 months.\",\n",
        "    \"Calculate [‚Äúnumber of days‚Äù selected] x [‚Äúnumber of minutes‚Äù selected] = [number of minutes of exercise per week] 2. Apply the right age threshold: Under 6 years old: You can‚Äôt find the physical activity need for people under 6. Age 6 to 17: Less than an average of 60 minutes a day shows an HRSN. Age 18 or older: Less than 150 minutes a week shows an HRSN.\",\n",
        "    \"Some people have made the following statements about their food situation\",\n",
        "    \"Because violence and abuse happens to a lot of people and affects their health\",\n",
        "    \"For example, starting or completing job training or getting a high school diploma, GED or equivalent.\",\n",
        "    \"Point Total:()\", \"when the numerical values for answers to questions 3-10 are added shows that the person might not be safe.\",\n",
        "    \"A score of 11 or more\", \"Follow these 2 steps to decide\",\n",
        "    \"The next questions relate to your experience with alcohol, cigarettes, and other drugs\",\n",
        "    \"If you get 3 or more when you add the answers to questions 23a and 23b\",\n",
        "    \"One drink is 12 ounces of beer, 5 ounces of wine, or 1.5 ounces of 80-proof spirits.\"\n",
        "]"
      ],
      "metadata": {
        "id": "H1Ev4T2sC7_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert PDF pages to images and extract text using OCR.\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    try:\n",
        "        images = convert_from_path(pdf_path)  # Converting PDF to images\n",
        "        text = \"\\n\".join([pytesseract.image_to_string(img, lang=\"eng\") for img in images])\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {pdf_path}: {e}\")\n",
        "        return None  # Skipping files that can't be processed"
      ],
      "metadata": {
        "id": "w5XxzsA3C_gh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean extracted text by removing unwanted symbols, spaces, and instructional texts.\n",
        "\n",
        "def clean_text(text):\n",
        "    text = re.sub(r\"[\\*+¬ª~‚Äî]\", \"\", text)\n",
        "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
        "    text = re.sub(r\"Powered by Kipu Systems Page \\d+ of \\d+\", \"\", text)\n",
        "\n",
        "    for unwanted in UNWANTED_TEXTS:\n",
        "        text = text.replace(unwanted, \"\")\n",
        "\n",
        "    return text.strip()"
      ],
      "metadata": {
        "id": "tfLxTiJIDHE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_questions_answers(text):\n",
        "\n",
        "    # Starting from the first valid question\n",
        "    start_section = \"1. What is your living situation today?\"\n",
        "    if start_section in text:\n",
        "        text = text.split(start_section, 1)[1]\n",
        "        text = start_section + \"\\n\" + text\n",
        "\n",
        "    question_pattern = re.compile(r\"(\\d+)\\.\\s(.*?\\?)\\s*(.*?)(?=\\n\\d+\\.|\\Z)\", re.DOTALL)\n",
        "\n",
        "    questions = []\n",
        "    answers = []\n",
        "\n",
        "    for match in question_pattern.finditer(text):\n",
        "        q_number, question, answer = match.groups()\n",
        "\n",
        "        if int(q_number) > 26:\n",
        "            break  # Stop at question 26\n",
        "\n",
        "        question = clean_text(question.strip())\n",
        "        answer = clean_text(answer.strip())\n",
        "\n",
        "        # Handling Question 23 sub-questions correctly\n",
        "        if q_number == \"23\":\n",
        "            sub_questions = re.findall(r\"(a\\.)\\s*(.*?)\\?(.*?)\\n(b\\.)\\s*(.*?)\\?(.*?)\", answer, re.DOTALL)\n",
        "            if sub_questions:\n",
        "                for sub_q in sub_questions:\n",
        "                    questions.append(f\"{question} {sub_q[1]}?\")\n",
        "                    answers.append(clean_text(sub_q[2]))\n",
        "\n",
        "                    questions.append(f\"{question} {sub_q[4]}?\")\n",
        "                    answers.append(clean_text(sub_q[5]))\n",
        "                continue\n",
        "\n",
        "        questions.append(question)\n",
        "        answers.append(answer)\n",
        "\n",
        "    return pd.DataFrame({\"Question\": questions, \"Answer\": answers})"
      ],
      "metadata": {
        "id": "QfQNpKf5DMlf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = extract_text_from_pdf(pdf_path)\n",
        "if text:\n",
        "    df = extract_questions_answers(text)"
      ],
      "metadata": {
        "id": "sYtBjifDEfA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "--S-p2UtEhJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Extraction using PDFPlumber"
      ],
      "metadata": {
        "id": "QN0bB2MYFOQL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Extraction from a single pdf"
      ],
      "metadata": {
        "id": "jWKgQ4LTFb7b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pdfplumber"
      ],
      "metadata": {
        "collapsed": true,
        "id": "UvCUdiSqFuMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfplumber"
      ],
      "metadata": {
        "id": "vzz2Q5wXFq__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract text from PDF using pdfplumber\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    try:\n",
        "        text = \"\"\n",
        "        with pdfplumber.open(pdf_path) as pdf:\n",
        "            for page in pdf.pages:\n",
        "                text += page.extract_text() + \"\\n\"\n",
        "        return text.strip()\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {pdf_path}: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "TxYxFKr2Fry4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = extract_text_from_pdf(pdf_path)\n",
        "if text:\n",
        "    df = extract_questions_answers(text)"
      ],
      "metadata": {
        "id": "PBP51b-dGHWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "j1VZtcqPG2ff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Tried manually entering 26 questions to create columns and also a pii which are extracted from thr filename to identify the patient.\n",
        "\n"
      ],
      "metadata": {
        "id": "cboZw86mTIP6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "w7BpOuptUe2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_folder = \"/content/drive/MyDrive/ahcm_redacted\""
      ],
      "metadata": {
        "id": "Sfn38TCmSlPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_from_pdf(pdf_path):\n",
        "    try:\n",
        "        text = \"\"\n",
        "        with pdfplumber.open(pdf_path) as pdf:\n",
        "            for page in pdf.pages:\n",
        "                page_text = page.extract_text()\n",
        "                if page_text:\n",
        "                    text += page_text + \"\\n\"\n",
        "\n",
        "        # Check if questions exist\n",
        "        if \"1. What is your living situation today?\" in text:\n",
        "            print(f\"Found Q&A section in {os.path.basename(pdf_path)}\")\n",
        "        else:\n",
        "            print(f\"No Q&A found in {os.path.basename(pdf_path)}. The questions might be on later pages.\")\n",
        "\n",
        "        return text.strip()\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {pdf_path}: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "eJ_ZuOxFUi5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    text = re.sub(r\"[\\*+¬ª~‚Äî]\", \"\", text)\n",
        "    text = re.sub(r\"(\\s)+\", \" \", text)\n",
        "    text = re.sub(r\"Powered by Kipu Systems Page \\d+ of \\d+\", \"\", text)\n",
        "\n",
        "    for unwanted in UNWANTED_TEXTS:\n",
        "        text = text.replace(unwanted, \"\")\n",
        "\n",
        "    return text.strip()"
      ],
      "metadata": {
        "id": "nGrs-IgnUmT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_questions_answers(text):\n",
        "    start_section = \"1. What is your living situation today?\"\n",
        "    if start_section in text:\n",
        "        text = text.split(start_section, 1)[1]\n",
        "        text = start_section + \"\\n\" + text\n",
        "    else:\n",
        "        print(\"No valid Q&A section found, skipping this PDF.\")\n",
        "        return None\n",
        "\n",
        "    question_pattern = re.compile(r\"(\\d+)\\.\\s(.*?)\\?(.*?)\\n(?=\\d+\\.|\\Z)\", re.DOTALL)\n",
        "\n",
        "    qa_dict = {question: None for question in QUESTION_COLUMNS}\n",
        "\n",
        "    for match in question_pattern.finditer(text):\n",
        "        q_number, question, answer = match.groups()\n",
        "        question = question.strip()\n",
        "        answer = answer.strip()\n",
        "\n",
        "        if question in qa_dict:\n",
        "            qa_dict[question] = answer\n",
        "\n",
        "    return qa_dict"
      ],
      "metadata": {
        "id": "hYBakM5mUozJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_pii_from_filename(filename):\n",
        "    match = re.search(r\"redacted_(\\w+)\\.pdf\", filename)\n",
        "    return match.group(1) if match else None"
      ],
      "metadata": {
        "id": "1U8cgetNUs_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_all_pdfs(pdf_folder):\n",
        "    data = []\n",
        "\n",
        "    for filename in os.listdir(pdf_folder):\n",
        "        if filename.endswith(\".pdf\"):\n",
        "            pdf_path = os.path.join(pdf_folder, filename)\n",
        "            text = extract_text_from_pdf(pdf_path)\n",
        "            if text:\n",
        "                answers_dict = extract_questions_answers(text)\n",
        "                pii_value = extract_pii_from_filename(filename)\n",
        "                answers_dict[\"PII\"] = pii_value\n",
        "                data.append(answers_dict)\n",
        "\n",
        "    return pd.DataFrame(data, columns=[\"PII\"] + QUESTION_COLUMNS)"
      ],
      "metadata": {
        "id": "gSzSrWyMUzcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "9TYuEKXoT8Zl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = process_all_pdfs(pdf_folder)\n",
        "\n",
        "text = extract_text_from_pdf(pdf_path)\n",
        "\n",
        "if text:\n",
        "    print(f\"üìù Extracted Q&A Text for {pdf_path}:\\n{text[:1000]}...\\n\")  # Printing first 1000 characters\n",
        "    extracted_data = extract_questions_answers(text)\n",
        "    print(extracted_data)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "OSGWytr_UZBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Data extraction is successful but currently trying to fix the dataframe issue as by debugging it is to be known that the data is stored as dictionary and just the value from those key:value pairs of each pdf's dictionary and store in the dataframe."
      ],
      "metadata": {
        "id": "gYguNe8yU7vW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "extracted_data"
      ],
      "metadata": {
        "id": "lpJ1iyytSnPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "collapsed": true,
        "id": "pIOpMkDaTFU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_from_pdf(pdf_path):\n",
        "    \"\"\"Extracts text from a single PDF file.\"\"\"\n",
        "    try:\n",
        "        text = \"\"\n",
        "        with pdfplumber.open(pdf_path) as pdf:\n",
        "            for page in pdf.pages:\n",
        "                page_text = page.extract_text()\n",
        "                if page_text:\n",
        "                    text += page_text + \"\\n\"\n",
        "\n",
        "        if \"1. What is your living situation today?\" in text:\n",
        "            print(f\"Found Q&A section in {os.path.basename(pdf_path)}\")\n",
        "        else:\n",
        "            print(f\"No Q&A found in {os.path.basename(pdf_path)}. It might be on later pages.\")\n",
        "\n",
        "        return text.strip()\n",
        "    except Exception as e:\n",
        "        print(f\" Error processing {pdf_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def extract_text_from_folder(pdf_folder):\n",
        "    \"\"\"Extracts text from all PDFs in a folder.\"\"\"\n",
        "    all_texts = {}  # Dictionary to store PDF filename -> extracted text\n",
        "\n",
        "    # Loop through all PDFs in the folder\n",
        "    for pdf_file in os.listdir(pdf_folder):\n",
        "        if pdf_file.endswith(\".pdf\"):\n",
        "            pdf_path = os.path.join(pdf_folder, pdf_file)\n",
        "            extracted_text = extract_text_from_pdf(pdf_path)\n",
        "            if extracted_text:\n",
        "                all_texts[pdf_file] = extracted_text\n",
        "\n",
        "    return all_texts  # Returns a dictionary of {pdf_filename: extracted_text}\n",
        "\n",
        "all_pdfs_text = extract_text_from_folder(pdf_folder)\n",
        "\n",
        "print(f\"\\n Extracted text from {len(all_pdfs_text)} PDFs.\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "LkZay2cRUZEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_pdfs_text"
      ],
      "metadata": {
        "collapsed": true,
        "id": "klZXOFiYUvFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_from_pdf(pdf_path):\n",
        "    \"\"\"Extracts text from a single PDF file.\"\"\"\n",
        "    try:\n",
        "        text = \"\"\n",
        "        with pdfplumber.open(pdf_path) as pdf:\n",
        "            for page in pdf.pages:\n",
        "                page_text = page.extract_text()\n",
        "                if page_text:\n",
        "                    text += page_text + \"\\n\"\n",
        "\n",
        "        return text.strip()\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Error processing {pdf_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def extract_qna_from_text(text):\n",
        "    \"\"\"Extracts Q&A pairs from the extracted text.\"\"\"\n",
        "    qa_dict = {}\n",
        "\n",
        "    # Define question pattern (modify regex if needed)\n",
        "    question_pattern = re.compile(r\"(\\d+\\.\\s.*?\\?)\\s*(.*)\")\n",
        "\n",
        "    # Extract Q&A pairs\n",
        "    for match in question_pattern.finditer(text):\n",
        "        question, answer = match.groups()\n",
        "        qa_dict[question.strip()] = answer.strip() if answer else None  # Handle missing answers\n",
        "\n",
        "    return qa_dict\n",
        "\n",
        "def process_all_pdfs(pdf_folder):\n",
        "    \"\"\"Processes all PDFs in a folder, extracting Q&A from each.\"\"\"\n",
        "    all_qna_data = []\n",
        "\n",
        "    for pdf_file in os.listdir(pdf_folder):\n",
        "        if pdf_file.endswith(\".pdf\"):  # Ensure it's a PDF\n",
        "            pdf_path = os.path.join(pdf_folder, pdf_file)\n",
        "            extracted_text = extract_text_from_pdf(pdf_path)\n",
        "\n",
        "            if extracted_text:  # Only process if text was extracted\n",
        "                print(f\"‚úÖ Processing {pdf_file}\")\n",
        "                qna_dict = extract_qna_from_text(extracted_text)\n",
        "\n",
        "                if qna_dict:  # Ensure we got valid Q&A pairs\n",
        "                    qna_dict[\"Filename\"] = pdf_file  # Add filename for reference\n",
        "                    all_qna_data.append(qna_dict)\n",
        "                else:\n",
        "                    print(f\"‚ö†Ô∏è No Q&A found in {pdf_file}\")\n",
        "\n",
        "    return all_qna_data\n",
        "\n",
        "# üìÇ Set your folder path\n",
        "pdf_folder = \"/content/drive/MyDrive/ahcm_redacted/\"\n",
        "\n",
        "# üîÑ Process all PDFs\n",
        "qna_data_list = process_all_pdfs(pdf_folder)\n",
        "\n",
        "# üìä Convert to DataFrame\n",
        "df = pd.DataFrame(qna_data_list)\n",
        "\n",
        "# üõ† Fill missing values with 'N/A' for consistency\n",
        "df.fillna(\"N/A\", inplace=True)\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "LewQwCVzVFMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "rUdGz2mTVxZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "UNWANTED_TEXTS = [\n",
        "    \"Living Situation\", \"Food\", \"Transportation\", \"Utilities\", \"Safety\",\n",
        "    \"Financial Strain\", \"Employment\", \"Family and Community Support\", \"Education\",\n",
        "    \"Physical Activity\", \"Substance Use\", \"Mental Health\", \"Disabilities\",\n",
        "    \"Choose all the apply\",\n",
        "    \"Please answer whether the statements were OFTEN, SOMETIMES, or NEVER true for you and your household in the last 12 months.\",\n",
        "    \"Calculate [‚Äúnumber of days‚Äù selected] x [‚Äúnumber of minutes‚Äù selected] = [number of minutes of exercise per week] 2. Apply the right age threshold: Under 6 years old: You can‚Äôt find the physical activity need for people under 6. Age 6 to 17: Less than an average of 60 minutes a day shows an HRSN. Age 18 or older: Less than 150 minutes a week shows an HRSN.\",\n",
        "    \"Some people have made the following statements about their food situation\",\n",
        "    \"Because violence and abuse happens to a lot of people and affects their health\",\n",
        "    \"For example, starting or completing job training or getting a high school diploma, GED or equivalent.\",\n",
        "    \"Point Total:()\", \"when the numerical values for answers to questions 3-10 are added shows that the person might not be safe.\",\n",
        "    \"A score of 11 or more\", \"Follow these 2 steps to decide\",\n",
        "    \"The next questions relate to your experience with alcohol, cigarettes, and other drugs\",\n",
        "    \"If you get 3 or more when you add the answers to questions 23a and 23b\",\n",
        "    \"One drink is 12 ounces of beer, 5 ounces of wine, or 1.5 ounces of 80-proof spirits.\"\n",
        "]\n",
        "\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"Cleans extracted text by removing unwanted characters and phrases.\"\"\"\n",
        "    text = re.sub(r\"[\\*+¬ª~‚Äî]\", \"\", text)  # Remove special characters\n",
        "    text = re.sub(r\"(\\s)+\", \" \", text)  # Normalize spaces\n",
        "    text = re.sub(r\"Powered by Kipu Systems Page \\d+ of \\d+\", \"\", text)  # Remove page numbers\n",
        "\n",
        "    for unwanted in UNWANTED_TEXTS:\n",
        "        text = text.replace(unwanted, \"\")\n",
        "\n",
        "    return text.strip()\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    \"\"\"Extracts text from a single PDF file.\"\"\"\n",
        "    try:\n",
        "        text = \"\"\n",
        "        with pdfplumber.open(pdf_path) as pdf:\n",
        "            for page in pdf.pages:\n",
        "                page_text = page.extract_text()\n",
        "                if page_text:\n",
        "                    text += page_text + \"\\n\"\n",
        "\n",
        "        if \"1. What is your living situation today?\" in text:\n",
        "            print(f\"Found Q&A section in {os.path.basename(pdf_path)}\")\n",
        "        else:\n",
        "            print(f\"No Q&A found in {os.path.basename(pdf_path)}. It might be on later pages.\")\n",
        "\n",
        "        return text.strip()\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {pdf_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def extract_text_from_folder(pdf_folder):\n",
        "    \"\"\"Extracts text from all PDFs in a folder.\"\"\"\n",
        "    all_texts = {}  # Dictionary to store PDF filename -> extracted text\n",
        "\n",
        "    # Loop through all PDFs in the folder\n",
        "    for pdf_file in os.listdir(pdf_folder):\n",
        "        if pdf_file.endswith(\".pdf\"):\n",
        "            pdf_path = os.path.join(pdf_folder, pdf_file)\n",
        "            extracted_text = extract_text_from_pdf(pdf_path)\n",
        "            if extracted_text:\n",
        "                all_texts[pdf_file] = extracted_text\n",
        "\n",
        "    return all_texts  # Returns a dictionary of {pdf_filename: extracted_text}\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"Cleans extracted text (removes unnecessary spaces, newlines, etc.).\"\"\"\n",
        "    return re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "def extract_questions_answers(text):\n",
        "    \"\"\"Extracts questions and answers from the extracted text.\"\"\"\n",
        "    # Starting from the first valid question\n",
        "    start_section = \"1. What is your living situation today?\"\n",
        "    if start_section in text:\n",
        "        text = text.split(start_section, 1)[1]\n",
        "        text = start_section + \"\\n\" + text\n",
        "\n",
        "    question_pattern = re.compile(r\"(\\d+)\\.\\s(.*?\\?)\\s*(.*?)(?=\\n\\d+\\.|\\Z)\", re.DOTALL)\n",
        "\n",
        "    questions = []\n",
        "    answers = []\n",
        "\n",
        "    for match in question_pattern.finditer(text):\n",
        "        q_number, question, answer = match.groups()\n",
        "\n",
        "        if int(q_number) > 26:\n",
        "            break  # Stop at question 26\n",
        "\n",
        "        question = clean_text(question.strip())\n",
        "        answer = clean_text(answer.strip())\n",
        "\n",
        "        # Handling Question 23 sub-questions correctly\n",
        "        if q_number == \"23\":\n",
        "            sub_questions = re.findall(r\"(a\\.)\\s*(.*?)\\?(.*?)\\n(b\\.)\\s*(.*?)\\?(.*?)\", answer, re.DOTALL)\n",
        "            if sub_questions:\n",
        "                for sub_q in sub_questions:\n",
        "                    questions.append(f\"{question} {sub_q[1]}?\")\n",
        "                    answers.append(clean_text(sub_q[2]))\n",
        "\n",
        "                    questions.append(f\"{question} {sub_q[4]}?\")\n",
        "                    answers.append(clean_text(sub_q[5]))\n",
        "                continue\n",
        "\n",
        "        questions.append(question)\n",
        "        answers.append(answer)\n",
        "\n",
        "    return pd.DataFrame({\"Question\": questions, \"Answer\": answers})\n",
        "\n",
        "def process_pdfs_in_folder(pdf_folder):\n",
        "    \"\"\"Processes all PDFs in a folder, extracting questions and answers.\"\"\"\n",
        "    all_pdfs_text = extract_text_from_folder(pdf_folder)\n",
        "\n",
        "    all_results = {}\n",
        "\n",
        "    for pdf_filename, text in all_pdfs_text.items():\n",
        "        print(f\"Extracting Q&A from {pdf_filename}...\")\n",
        "        df = extract_questions_answers(text)\n",
        "        all_results[pdf_filename] = df\n",
        "\n",
        "    return all_results\n",
        "\n",
        "\n",
        "\n",
        "pdf_folder = \"/content/drive/MyDrive/ahcm_redacted/\"\n",
        "all_pdf_data = process_pdfs_in_folder(pdf_folder)\n",
        "\n",
        "\n",
        "for pdf_filename, df in all_pdf_data.items():\n",
        "    print(f\"\\nExtracted Q&A from {pdf_filename}:\")\n",
        "    print(df.head())\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "iA_7NfH3sHdf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(all_pdf_data)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "_QWiSlQisl0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "------\n"
      ],
      "metadata": {
        "id": "iNyXA8hDzZzl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "UNWANTED_TEXTS = [\n",
        "    \"Living Situation\", \"Food\", \"Transportation\", \"Utilities\", \"Safety\",\n",
        "    \"Financial Strain\", \"Employment\", \"Family and Community Support\", \"Education\",\n",
        "    \"Physical Activity\", \"Substance Use\", \"Mental Health\", \"Disabilities\",\n",
        "    \"Choose all the apply\",\n",
        "    \"Please answer whether the statements were OFTEN, SOMETIMES, or NEVER true for you and your household in the last 12 months.\",\n",
        "    \"Calculate [‚Äúnumber of days‚Äù selected] x [‚Äúnumber of minutes‚Äù selected] = [number of minutes of exercise per week] 2. Apply the right age threshold: Under 6 years old: You can‚Äôt find the physical activity need for people under 6. Age 6 to 17: Less than an average of 60 minutes a day shows an HRSN. Age 18 or older: Less than 150 minutes a week shows an HRSN.\",\n",
        "    \"Some people have made the following statements about their food situation\",\n",
        "    \"Because violence and abuse happens to a lot of people and affects their health\",\n",
        "    \"For example, starting or completing job training or getting a high school diploma, GED or equivalent.\",\n",
        "    \"Point Total:()\", \"when the numerical values for answers to questions 3-10 are added shows that the person might not be safe.\",\n",
        "    \"A score of 11 or more\", \"Follow these 2 steps to decide\",\n",
        "    \"The next questions relate to your experience with alcohol, cigarettes, and other drugs\",\n",
        "    \"If you get 3 or more when you add the answers to questions 23a and 23b\",\n",
        "    \"One drink is 12 ounces of beer, 5 ounces of wine, or 1.5 ounces of 80-proof spirits.\"\n",
        "]\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"Cleans extracted text by removing unwanted characters and phrases.\"\"\"\n",
        "    text = re.sub(r\"[\\*+¬ª~‚Äî]\", \"\", text)\n",
        "    text = re.sub(r\"(\\s)+\", \" \", text)\n",
        "    text = re.sub(r\"Powered by Kipu Systems Page \\d+ of \\d+\", \"\", text)\n",
        "\n",
        "    for unwanted in UNWANTED_TEXTS:\n",
        "        text = text.replace(unwanted, \"\")\n",
        "\n",
        "    return text.strip()\n",
        "\n",
        "\n",
        "all_responses = []\n",
        "\n",
        "\n",
        "for pdf_filename, df in all_pdf_data.items():\n",
        "    cleaned_questions = df['Question'].apply(clean_text).tolist()\n",
        "    cleaned_answers = df['Answer'].apply(clean_text).tolist()\n",
        "    all_responses.append(cleaned_answers)\n",
        "\n",
        "final_df = pd.DataFrame(all_responses, columns=cleaned_questions)\n",
        "print(final_df)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "MooV36HVyeeL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df"
      ],
      "metadata": {
        "id": "cWGhxAVZykJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.to_csv(\"ahcm_output_data.csv\", index=False)"
      ],
      "metadata": {
        "id": "BBJCSoF41P01"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}