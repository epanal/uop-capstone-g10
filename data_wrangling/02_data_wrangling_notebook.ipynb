{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35a0235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdff3683",
   "metadata": {},
   "source": [
    "## 1. Merging Individual Assessments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69c71a3",
   "metadata": {},
   "source": [
    "**Note:** Each folder consist of all individual patient CSV files for a particular assessment. Each raw CSV file contains records that have a different query/question at a particular date in time.  The resulting post-processed dataframes will merge all individual CSV files (for a particular assessment) and process them so that at a specific date in time we have the responses to each question within a single record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93fc5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder path for assessment CSV files - WHO\n",
    "folder_path = '/Users/bk/Desktop/exist_centers/data/who'\n",
    "\n",
    "# # folder path for assessment CSV files - GAD\n",
    "# folder_path = '/Users/bk/Desktop/exist_centers/data/gad'\n",
    "\n",
    "# # folder path for assessment CSV files - PHQ\n",
    "# folder_path = '/Users/bk/Desktop/exist_centers/data/phq'\n",
    "\n",
    "# # folder path for assessment CSV files - PTSD\n",
    "# folder_path = '/Users/bk/Desktop/exist_centers/data/ptsd'\n",
    "\n",
    "# # folder path for assessment CSV files - DERS\n",
    "# folder_path = '/Users/bk/Desktop/exist_centers/data/ders'\n",
    "\n",
    "# # folder path for assessment CSV files - DERS2\n",
    "# folder_path = '/Users/bk/Desktop/exist_centers/data/ders2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fddbb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all CSV files in folder\n",
    "csv_files = glob(os.path.join(folder_path, '*.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb38035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize empty list to store data frames\n",
    "df_list = list()\n",
    "\n",
    "# loop thru CSV files and process\n",
    "for file_path in csv_files:\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # add a new column w/ file name\n",
    "    df['file_name'] = os.path.basename(file_path)\n",
    "    \n",
    "    # add to list\n",
    "    df_list.append(df)\n",
    "\n",
    "# merge all data frames\n",
    "combined_df = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2bb8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e09d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize empty list to store data frames\n",
    "df_list = list()\n",
    "\n",
    "# loop thru CSV files and process\n",
    "for file_path in csv_files:\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # add a new column w/ file name\n",
    "    df['file_name'] = os.path.basename(file_path)\n",
    "    \n",
    "    # identify question-related columns\n",
    "    fixed_columns = ['question', 'code', 'issue', 'issue_code', 'file_name']\n",
    "    \n",
    "    # identify date columns\n",
    "    date_columns = [col for col in df.columns if col not in fixed_columns]\n",
    "    \n",
    "    # reshape using pd.melt so that each date becomes a row\n",
    "    df_melted = df.melt(id_vars=fixed_columns, \n",
    "                         value_vars=date_columns, \n",
    "                         var_name='assessment_date', \n",
    "                         value_name='response')\n",
    "    \n",
    "    # add to list\n",
    "    df_list.append(df_melted)\n",
    "\n",
    "# merge all data frames\n",
    "df_combined = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# pivot so that question types become columns\n",
    "df_final = df_combined.pivot_table(index=['file_name', 'assessment_date'], \n",
    "                                   columns='question', \n",
    "                                   values='response', \n",
    "                                   aggfunc='first').reset_index()\n",
    "\n",
    "df_final.columns.name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c87da7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f66a8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # remove multi-index column naming\n",
    "# df_final.columns.name = None\n",
    "\n",
    "# extract first name, last name, and date part of file name\n",
    "first_name = df_final['file_name'].apply(lambda x: x.split('_')[1] if len(x.split('_')) >= 4 else None)\n",
    "last_name = df_final['file_name'].apply(lambda x: x.split('_')[2] if len(x.split('_')) >= 4 else None)\n",
    "\n",
    "# full name: combin first and last name\n",
    "df_final['full_name'] = first_name + \" \" + last_name\n",
    "\n",
    "# extract the date_part of file name\n",
    "df_final['date_part'] = df_final['file_name'].apply(lambda x: x.split('_')[3] if len(x.split('_')) >= 4 else None)\n",
    "\n",
    "# # # reorder columns\n",
    "# final_df = final_df.iloc[:, [0,8,9,1,2,3,4,5,6,7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22dbe26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_final.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a46c530",
   "metadata": {},
   "source": [
    "## 2. Merging with Full Patient List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc9365a",
   "metadata": {},
   "source": [
    "**Note:** Here, we will merge our post-processed dataframe with the full patient list that contains each patients full name, MR/ID #, group identifier, and initial group identifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3579441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load full patient version 2 CSV file\n",
    "df_patient = pd.read_csv('/Users/bk/Desktop/exist_centers/data/patient_listv2.csv')\n",
    "\n",
    "# merge dataframes to get patient ID\n",
    "df_final = df_final.merge(df_patient[['full_name','patient_ID','group_identifier','initial_group_identifier']], on='full_name')\n",
    "\n",
    "# print top 5 rows\n",
    "df_final.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3259b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pseudonymization \n",
    "# SECRET_KEY = \"THIS IS A SECRET!\"\n",
    "\n",
    "# name_mapping = dict()\n",
    "\n",
    "# def pseudonymize_function(patient_id):\n",
    "#     if patient_id not in name_mapping:\n",
    "#         hash_input = (SECRET_KEY + patient_id).encode()\n",
    "#         hashed_value = hashlib.sha256(hash_input).hexdigest()[:12]\n",
    "#         name_mapping[patient_id] = f\"{hashed_value}\"\n",
    "#     return name_mapping[patient_id]\n",
    "\n",
    "# # apply pseudonymization function\n",
    "# df_final['group_identifier'] = df_final['patient_ID'].apply(lambda x: pseudonymize_function(x) if pd.notnull(x) else None)\n",
    "\n",
    "# # # # reorder columns \n",
    "# # df_final = df_final.iloc[:, [0,8,10,9,1,2,3,4,5,6,7]]\n",
    "\n",
    "# column_order = [\"file_name\", \"group_identifier\", \"date_part\", \"assessment_date\"] + \\\n",
    "#                [col for col in df_final.columns if col not in [\"file_name\", \"group_identifier\", \"date_part\", \"assessment_date\", \"full_name\"]]\n",
    "\n",
    "# df_final = df_final[column_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c88f67b",
   "metadata": {},
   "source": [
    "**Comment:** The pseudonmiation process was moved to the previous notebook *(01_extract_patient_list_notebook)*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9e609c",
   "metadata": {},
   "source": [
    "## 3. Removing Personally Identifiable Information (PII) columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbf927f",
   "metadata": {},
   "source": [
    "**Note:** This section will remove all PII data for safe and secure handoff to the rest of the team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20d4655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset dataframe: remove all PII columns\n",
    "df_anon = df_final.drop(columns=['file_name','full_name','patient_ID'])\n",
    "# df_anon = df_final.iloc[:,1:-1]\n",
    "\n",
    "# rename column for readability\n",
    "df_anon.rename(columns={'date_part':'file_part'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dec9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anon.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1221b51e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_anon.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56523b6",
   "metadata": {},
   "source": [
    "## 4. Handling duplicate records due to multiple MR/ID #'s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d022f4d0",
   "metadata": {},
   "source": [
    "**Note:** Due to some patients having multiple MR/ID numbers, this also created multiple group identifiers for the same patient since we pseudonymized using patient MR/ID #. However, the initial group identifier column in the full patient list dataframe assigns a single unique ID for each patient. Therefore, we will drop the group identifier field and remove duplicate recrods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ff9b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anon2 = df_anon.drop(columns=['group_identifier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b249fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anon2[df_anon2.duplicated(keep=False)].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499f4fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-order columns for readability\n",
    "cols = ['initial_group_identifier', 'file_part','assessment_date'] + [col for col in df_anon2.columns if col not in ['initial_group_identifier','file_part','assessment_date']]\n",
    "df_anon2 = df_anon2[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1f1d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removes duplicates\n",
    "df_anon2 = df_anon2.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1816e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "df_anon2[df_anon2.duplicated(keep=False)].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d183f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anon2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ce9922",
   "metadata": {},
   "source": [
    "## 5. Save Final Anonomyzed Data Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb6303e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save final merged CSV - WHO\n",
    "# df_anon2.to_csv('who_merged.csv', index=False)\n",
    "\n",
    "# # save final merged CSV - GAD\n",
    "# df_anon2.to_csv('gad_merged.csv', index=False)\n",
    "\n",
    "# # save final merged CSV - PHQ\n",
    "# df_anon2.to_csv('phq_merged.csv', index=False)\n",
    "\n",
    "# # save final merged CSV - PTSD\n",
    "# df_anon2.to_csv('ptsd_merged.csv', index=False)\n",
    "\n",
    "# # save final merged CSV - DERS\n",
    "# df_anon2.to_csv('ders_merged.csv', index=False)\n",
    "\n",
    "# # save final merged CSV - DERS2 \n",
    "# df_anon2.to_csv('ders2_merged.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4315f1ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
